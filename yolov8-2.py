# -*- coding: utf-8 -*-
"""yolov8

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/maryamali004/yolov8.9e0c2ad9-7f0f-4a72-b39c-6f690085f214.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250514/auto/storage/goog4_request%26X-Goog-Date%3D20250514T110359Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D879b5d8acf9e98415eb393bcf77ead913d9f0e8f264ffd73c31b5be08c57ea865080e2bb2b5a1e843cda25742ceaac6631d0986bbc9e2db47f7a1d219c093d2ef8f78d88a84cb7d40221c458c87d8901f2d6a5f689317ce0c9852a6466f577c3a8233baf6d93ebdc687300df7255089e0fcdf328670c23304e5e678c3fce87cf0cd657859d011d7ab2bd5bbab160556d0557f53dff90b847ba09c9b89c4b18a60a00e075217ba5a331d38cf29b8db87c98922e6c1a0db5ba94a5ca83e643ed3c0f998988845559ae94aa122c742e5d340badbe0a7ae39a0bb1a08b98548c716a7b140f7fa927dae4632c163e79f25d664fc3eb72ba568c9d6d0219fb42c25cea
"""

from ultralytics import YOLO
from torchvision.models import mobilenet_v2
from torchvision.models._utils import IntermediateLayerGetter
import torch.nn as nn
import torch

class MobileNetV2Backbone(nn.Module):
    def __init__(self, weights='IMAGENET1K_V1'):
        super().__init__()
        # Load pretrained MobileNetV2
        backbone = mobilenet_v2(weights=weights).features

        # Extract multi-scale features
        self.feature_extractor = IntermediateLayerGetter(
            backbone,
            return_layers={'6': 'c3', '13': 'c4', '18': 'c5'}
        )

        # Channel adjustment with proper initialization
        self.adapt_convs = nn.ModuleList([
            nn.Conv2d(32, 256, 1),
            nn.Conv2d(96, 512, 1),
            nn.Conv2d(1280, 1024, 1)
        ])

        # Initialize normalization parameters on same device as model
        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))
        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))

    def forward(self, x):
        # Ensure same device for all tensors
        device = x.device
        x = x.float().to(device) / 255.0
        x = (x - self.mean.to(device)) / self.std.to(device)

        features = self.feature_extractor(x)
        return [
            self.adapt_convs[0](features['c3'].to(device)),
            self.adapt_convs[1](features['c4'].to(device)),
            self.adapt_convs[2](features['c5'].to(device))
        ]

def test_model():
    # Initialize model on proper device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = YOLO('yolov8n.yaml').to(device)
    model.model.backbone = MobileNetV2Backbone().to(device)

    # Create dummy input on same device
    dummy_input = torch.randint(0, 255, (1, 3, 640, 640),
                     dtype=torch.float32, device=device)

    # Forward pass
    with torch.no_grad():
        results = model(dummy_input)

    print("\nDetection output:", results[0].boxes)

    # Verify backbone features
    backbone_features = model.model.backbone(dummy_input)
    print("\nBackbone features:")
    for i, feat in enumerate(backbone_features):
        print(f"Layer {i+1}: {feat.shape} ({feat.device})")

if __name__ == '__main__':
    test_model()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# Reinitialize with proper config
model = YOLO('yolov8n.yaml')
model.model.backbone = MobileNetV2Backbone().to(device)
results = model.train(
    data='/home/jovyan/workspace/cctv_car_bike_detection-3/data.yaml',
    epochs=500,
    imgsz=640,
    batch=16,  # Safer batch size for most GPUs
    lr0=0.01,  # Optimal starting point for MobileNet backbone
    lrf=1e-4,  # Gentle cosine annealing
    optimizer='Adam',  # More stable than AdamW for detection
    augment=True,  # Basic augmentations
    hsv_h=0.1,  # Moderate color augmentation
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=10.0,  # Reasonable rotation
    flipud=0.25,  # Vertical flip
    fliplr=0.5,  # Horizontal flip
    mosaic=0.75,  # Partial mosaic
    mixup=0.1,  # Mild mixup
    patience=100,  # Early stopping
    weight_decay=0.0005,  # Light regularization
    device=device
)

metrics = model.val(
    data='/home/jovyan/workspace/cctv_car_bike_detection-3/data.yaml',
    split='test',
    plots=True,
    conf=0.25,
    iou=0.45
)


# 3. Visualize predictions
test_images = ['workspace/cctv_car_bike_detection-3/test/images/270_jpg.rf.a5ad6663c35365c7001f08d11c6edee1.jpg']
results = model.predict(test_images, save=True, line_width=2)

# 4. Display results
import matplotlib.pyplot as plt
for r in results:
    plt.figure(figsize=(12, 8))
    plt.imshow(r.plot()[:, :, ::-1])  # Convert BGR to RGB
    plt.axis('off')
    plt.show()

# 5. Access model weights directly from memory (if needed)
torch.save(model.model.state_dict(), 'mobile_backbone_yolo_weights.pt')

from torchvision.models import vgg16
class VGG16Backbone(nn.Module):
    def __init__(self, weights='IMAGENET1K_V1'):
        super().__init__()
        # Load pretrained VGG16
        backbone = vgg16(weights=weights).features

        # Extract features from specific blocks
        self.feature_extractor = IntermediateLayerGetter(
            backbone,
            return_layers={
                '16': 'c3',  # Block3 output (stride 8)
                '23': 'c4',  # Block4 output (stride 16)
                '30': 'c5'   # Block5 output (stride 32)
            }
        )

        # Channel adjustment
        self.adapt_convs = nn.ModuleList([
            nn.Conv2d(256, 256, 1),   # c3 adjustment
            nn.Conv2d(512, 512, 1),   # c4 adjustment
            nn.Conv2d(512, 1024, 1)   # c5 adjustment
        ])

        # Normalization parameters
        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))
        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))

    def forward(self, x):
        # Normalize input
        x = x.float() / 255.0
        x = (x - self.mean.to(x.device)) / self.std.to(x.device)

        # Extract features
        features = self.feature_extractor(x)
        return [
            self.adapt_convs[0](features['c3']),
            self.adapt_convs[1](features['c4']),
            self.adapt_convs[2](features['c5'])
        ]

# Initialize model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = YOLO('yolov8n.yaml').to(device)
model.model.backbone = VGG16Backbone().to(device)

# Training configuration
results = model.train(
    data='/home/jovyan/workspace/cctv_car_bike_detection-3/data.yaml',
    epochs=500,
    batch=16,
    lr0=1e-3,
    lrf=1e-4,
    optimizer='Adam',
    augment=True,
    hsv_h=0.1,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=15.0,
    flipud=0.25,
    fliplr=0.5,
    mosaic=0.75,
    mixup=0.1,
    weight_decay=0.0005,
    device=device
)

# Create save directory
os.makedirs('saved_models', exist_ok=True)

# 1. Save complete model (recommended)
model.save('saved_models/vgg16_yolov8.pt')

model = YOLO("saved_models/vgg16_yolov8.pt")

metrics = model.val(
    data='/home/jovyan/workspace/cctv_car_bike_detection-3/data.yaml',
    split='test',
    plots=True,
    conf=0.25,
    iou=0.45
)

# 4. Display results
import matplotlib.pyplot as plt
for r in results:
    plt.figure(figsize=(12, 8))
    plt.imshow(r.plot()[:, :, ::-1])  # Convert BGR to RGB
    plt.axis('off')
    plt.show()

# 3. Visualize predictions
test_images = ['workspace/cctv_car_bike_detection-3/test/images/CCTV-12_729_jpg.rf.d0004add05cef58501f8c6bec340ba28.jpg']
results = model.predict(test_images, save=True, line_width=2)

